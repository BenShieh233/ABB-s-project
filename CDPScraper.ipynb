{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import lxml\n",
    "import getpass\n",
    "from IPython.display import display, Image\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--disable-gpu')\n",
    "options.add_argument('--disable-dve-shm-uage')\n",
    "options.add_argument('ignore-certificate-errors')\n",
    "options.add_argument('--ignore-ssl-errors=yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_screen():\n",
    "    bot.save_screenshot(\"out.png\")\n",
    "    display(Image(\"out.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'bensshieh4333@gmail.com'\n",
    "password = 'Ben23340020`'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Login Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_login():\n",
    "    url = 'https://www.cdp.net/en/users/sign_in'\n",
    "    bot = webdriver.Chrome(options=options)\n",
    "    wait = WebDriverWait(bot, 20)\n",
    "    bot.get(url)\n",
    "    wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"#onetrust-accept-btn-handler\"))).click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    bot.find_element(By.ID, 'user_email').send_keys(username)\n",
    "    bot.find_element(By.ID, 'user_password').send_keys(password)\n",
    "    button = bot.find_element(By.CSS_SELECTOR, \"button[type='submit']\")\n",
    "    button.click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    bot.get('https://www.cdp.net/en/scores')\n",
    "\n",
    "    popup_button = bot.find_element(By.CLASS_NAME, \"ga-track-regional-popup-item-north-america\")\n",
    "    popup_button.click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    return bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Search Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_company(bot, company_name):\n",
    "    input_box = bot.find_element(By.ID, \"queries_name\")\n",
    "    input_box.send_keys(company_name)\n",
    "    submit_button = bot.find_element(By.CLASS_NAME, \"response_search_form--btn\")\n",
    "    submit_button.click()\n",
    "\n",
    "    link = bot.find_element(By.CSS_SELECTOR, \"a.pagination__per_page--selected\")\n",
    "    href = link.get_attribute('href')\n",
    "    href = href.replace('page=5', 'page=20')\n",
    "    bot.get(href)\n",
    "\n",
    "    return bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Search Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper(bot, year):\n",
    "    # Find the table by its class name (or other suitable selector)\n",
    "    table = bot.find_element(By.CLASS_NAME, \"sortable_table\")\n",
    "\n",
    "    # Extract all rows from the table\n",
    "    rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "    # Initialize lists to store data and hrefs\n",
    "    data = []\n",
    "    hrefs = []\n",
    "\n",
    "    # Extract data from each row\n",
    "    for row in rows[1:]:  # Skip the header row\n",
    "        cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        row_data = []\n",
    "        row_hrefs = []\n",
    "        for i, col in enumerate(cols):\n",
    "            links = col.find_elements(By.TAG_NAME, \"a\")\n",
    "            if links:\n",
    "                # Extract text and href for each link\n",
    "                link_text = links[0].text\n",
    "                link_href = links[0].get_attribute('href')\n",
    "                row_data.append(link_text)\n",
    "                row_hrefs.append(link_href)\n",
    "            else:\n",
    "                # If no link, add the text and a None for href\n",
    "                row_data.append(col.text)\n",
    "                row_hrefs.append(None)\n",
    "        \n",
    "        data.append(row_data)\n",
    "        hrefs.append(row_hrefs)\n",
    "\n",
    "    # Create a DataFrame from the extracted data\n",
    "    column_headers = [col.text for col in rows[0].find_elements(By.TAG_NAME, \"th\")]\n",
    "    df = pd.DataFrame(data, columns=column_headers)\n",
    "\n",
    "    # Add the hrefs as a new column\n",
    "    df['Response Links'] = pd.Series([href[1] for href in hrefs])\n",
    "\n",
    "    df = df[df['Year'] == year]\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_section(row):\n",
    "\n",
    "    if row['Response'] == 'Climate Change 2023':\n",
    "        bot.get(row['Response Links'])\n",
    "        WebDriverWait(bot, 10).until(EC.visibility_of_element_located((By.ID, 'formatted_responses_section_31715')))\n",
    "        scraped_text = bot.find_element(By.ID, 'formatted_responses_section_31715').text\n",
    "    elif row['Response'] == 'Forests 2023':\n",
    "        bot.get(row['Response Links'])\n",
    "        WebDriverWait(bot, 10).until(EC.visibility_of_element_located((By.ID, 'formatted_responses_section_90809')))\n",
    "        scraped_text = bot.find_element(By.ID, 'formatted_responses_section_90809').text    \n",
    "    elif row['Response'] == 'Water Security 2023':\n",
    "        bot.get(row['Response Links'])\n",
    "        WebDriverWait(bot, 10).until(EC.visibility_of_element_located((By.ID, 'formatted_responses_section_31639')))\n",
    "        scraped_text = bot.find_element(By.ID, 'formatted_responses_section_31639').text   \n",
    "\n",
    "    else:\n",
    "        scraped_text = 'Unknown Response Type'\n",
    "\n",
    "    return scraped_text\n",
    "\n",
    "    \n",
    "def apply_scraping(df):\n",
    "    global bot\n",
    "\n",
    "    df['text'] = df.apply(find_section, axis=1)\n",
    "\n",
    "    bot.quit()\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Response</th>\n",
       "      <th>Year</th>\n",
       "      <th>Status</th>\n",
       "      <th>Score</th>\n",
       "      <th>Response Links</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>General Mills Inc.</td>\n",
       "      <td>Climate Change 2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>Submitted</td>\n",
       "      <td>Not Scored</td>\n",
       "      <td>https://www.cdp.net/en/cdp2/redirect?campaign_...</td>\n",
       "      <td>C4.3b\\n(C4.3b) Provide details on the initiati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>General Mills Inc.</td>\n",
       "      <td>Forests 2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>Submitted</td>\n",
       "      <td>Not Scored</td>\n",
       "      <td>https://www.cdp.net/en/cdp2/redirect?campaign_...</td>\n",
       "      <td>F6.11\\n(F6.11) Do you participate in any other...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>General Mills Inc.</td>\n",
       "      <td>Water Security 2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>Submitted</td>\n",
       "      <td>Not Scored</td>\n",
       "      <td>https://www.cdp.net/en/cdp2/redirect?campaign_...</td>\n",
       "      <td>W8.1b\\n(W8.1b) Provide details of your water-r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name             Response  Year     Status       Score  \\\n",
       "0  General Mills Inc.  Climate Change 2023  2023  Submitted  Not Scored   \n",
       "1  General Mills Inc.         Forests 2023  2023  Submitted  Not Scored   \n",
       "2  General Mills Inc.  Water Security 2023  2023  Submitted  Not Scored   \n",
       "\n",
       "                                      Response Links  \\\n",
       "0  https://www.cdp.net/en/cdp2/redirect?campaign_...   \n",
       "1  https://www.cdp.net/en/cdp2/redirect?campaign_...   \n",
       "2  https://www.cdp.net/en/cdp2/redirect?campaign_...   \n",
       "\n",
       "                                                text  \n",
       "0  C4.3b\\n(C4.3b) Provide details on the initiati...  \n",
       "1  F6.11\\n(F6.11) Do you participate in any other...  \n",
       "2  W8.1b\\n(W8.1b) Provide details of your water-r...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_name = 'General Mills Inc.'\n",
    "year = '2023'\n",
    "bot = page_login() # Login to the website\n",
    "bot = search_company(bot, company_name) # Enter company name\n",
    "df = scraper(bot, year) # Specify the year\n",
    "df_updated = apply_scraping(df)\n",
    "df_updated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
